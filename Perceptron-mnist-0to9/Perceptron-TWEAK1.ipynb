{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.93684159  1.81802157  1.79301854]\n"
     ]
    }
   ],
   "source": [
    "# %load perceptron.py\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class Perceptron:\n",
    "\n",
    "    def __init__(self,input):\n",
    "        self.W = np.zeros(input.shape[1]+1) ## weight vector\n",
    "        ## +1 slot cause of bias in input\n",
    "        self.bias = 1\n",
    "        self.lr = 0.1 ##learning rate\n",
    "        self.epoch = 100\n",
    "\n",
    "    def predict(self,input):\n",
    "        x = np.insert(input,0,1) # x0 = 1, for bias\n",
    "        net = np.inner(self.W,x)\n",
    "        s = self.sigmoid(net)\n",
    "        return s if s >= 0.5 else 0.0\n",
    "\n",
    "    def fit(self,input,d):\n",
    "        for i in range(self.epoch):\n",
    "            for j in range(d.shape[0]):\n",
    "                t = np.array(input.iloc[j])\n",
    "                x = np.insert(t,0,1) # x0 = 1, for bias\n",
    "                net = np.inner(self.W,x)\n",
    "                y = self.sigmoid(net)\n",
    "                self.W = self.W + self.lr * (d[j]-y)*x\n",
    "                \n",
    "    def step_function(self,value):\n",
    "        return 1.0 if value >= 0.0 else 0.0    \n",
    "    \n",
    "    def sigmoid(self,value):\n",
    "        if -value > np.log(np.finfo(type(value)).max):\n",
    "            return 0.0    \n",
    "        a = np.exp(-value)\n",
    "        return 1.0/ (1.0 + a) \n",
    "        \n",
    "    def testPrediction(self, input, y_expected):\n",
    "        hits = 0\n",
    "        acc = 0\n",
    "        for i in range(input.shape[0]):\n",
    "            t = np.array(input.iloc[i])\n",
    "            x = np.insert(t,0,1) # x0 = 1, for bias\n",
    "            y = self.sigmoid( np.inner(self.W,x) )\n",
    "            if y == y_expected[i]:\n",
    "                hits += 1\n",
    "        acc = hits / input.shape[0]\n",
    "        print('Accuracy: {}'.format(acc))\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    X_input = pd.DataFrame([\n",
    "    [0,0],[0,1],[1,0],[1,1]\n",
    "    ])\n",
    "    exp_out = np.array([0,0,0,1])\n",
    "    perceptron = Perceptron(X_input)\n",
    "    perceptron.fit(X_input,exp_out)\n",
    "    print(perceptron.W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('mnist_test.csv')\n",
    "df_train = pd.read_csv('mnist_train.csv')\n",
    "\n",
    "y_train,X_train = np.split(df_train,[1], axis=1)  ## Splits DataFrame into Labels // Training sets\n",
    "y_test,X_test = np.split(df_test,[1], axis=1)  ## Splits DataFrame into Labels // Training sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##      onde for == 1, troca por 1, se nao 0   ;;; treina o perceptron a ver somente o numero 1\n",
    "Y_train = np.where(y_train['5'] == 1, 1, 0)  ##normalizes input so perceptron sees it as 1/0\n",
    "Y_test = np.where(y_test['7'] == 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sorted = df_train.sort_values(by=['5'])\n",
    "a = df_train['5'].value_counts(sort = True, ascending = True)\n",
    "lowest_sample_amount = a.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df = df_train\n",
    "for i in df_train['5'].unique():\n",
    "    drop_amount = a[i] - lowest_sample_amount  ##gets amount of rows to be dropped\n",
    "    tmp = df_train[df_train['5'] == i]  ##select all == to label\n",
    "    indexes = tmp.sample(n= drop_amount).index           ## get indexes to be dropped\n",
    "    normalized_df = normalized_df.drop(indexes)         ## normalized df will have same number of every sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron 0 obteve:\n",
      "Accuracy: 0.967996799679968\n",
      "Perceptron 1 obteve:\n",
      "Accuracy: 0.9731973197319732\n",
      "Perceptron 2 obteve:\n",
      "Accuracy: 0.9621962196219622\n",
      "Perceptron 3 obteve:\n",
      "Accuracy: 0.888988898889889\n",
      "Perceptron 4 obteve:\n",
      "Accuracy: 0.931893189318932\n",
      "Perceptron 5 obteve:\n",
      "Accuracy: 0.953995399539954\n",
      "Perceptron 6 obteve:\n",
      "Accuracy: 0.9572957295729573\n",
      "Perceptron 7 obteve:\n",
      "Accuracy: 0.9547954795479549\n",
      "Perceptron 8 obteve:\n",
      "Accuracy: 0.917991799179918\n",
      "Perceptron 9 obteve:\n",
      "Accuracy: 0.8121812181218122\n"
     ]
    }
   ],
   "source": [
    "perceptrons = []\n",
    "for i in range(10): \n",
    "    perceptrons.append(Perceptron(X_train))   ##create 10 perceptrons\n",
    "    \n",
    "for i in range(10):\n",
    "    tmp = []\n",
    "    tmp2 = []\n",
    "    ### prepares data\n",
    "    final_df = normalized_df\n",
    "    for j in range(10):  ## this for loop organizes the data before training perceptron\n",
    "        if j != i:\n",
    "            sets_per_value = math.floor(lowest_sample_amount/9)\n",
    "            \n",
    "            df_tmp = normalized_df[ normalized_df['5'] == j ]\n",
    "            indexes = df_tmp.sample(n= (lowest_sample_amount - sets_per_value) ).index   ##if yes group 5000, then drop (5000 - 554)...\n",
    "            final_df = final_df.drop(indexes)\n",
    "    \n",
    "    y_train_final,X_train_final = np.split(final_df,[1],axis=1)  ##splits data into labels // data\n",
    "    \n",
    "    tmp.append( np.where(y_train_final['5'] == i, 1 , 0) )  #changes labels to 1/0 in training data\n",
    "    tmp2.append( np.where(y_test['7'] == i, 1 , 0) )         #changes labels to 1/0 in test data\n",
    "    \n",
    "    y_train_array = np.array(tmp)  \n",
    "    y_test_array = np.array(tmp2)\n",
    "    #print(perceptrons)\n",
    "    perceptrons[i].fit(X_train_final,y_train_array[0])   ##training\n",
    "    print('Perceptron {} obteve:'.format(i))\n",
    "    perceptrons[i].testPrediction(X_test,y_test_array[0])   ##testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tests all 10 perceptrons with test data\n",
    "predictions = []\n",
    "for i in range(X_test.shape[0]):  #for each input \n",
    "    test_ar = np.array(X_test.iloc[i])  #cast to np.array\n",
    "    p = [] \n",
    "    for j in range(10):\n",
    "        p.append( perceptrons[j].predict(test_ar) )  #appends perceptrons predictions to array\n",
    "    \n",
    "    predictions.append( p.index( max(p) ) )  #perceptron with highest value is probably right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(predictions, columns=['q'])  ## creates dataFrame with results\n",
    "\n",
    "res = np.where((df_test['q'] == y_test['7']), 1, 0)  ##compares expected results dataFrame with test-results dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7416741674167416"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits = np.count_nonzero(res == 1)\n",
    "f_accuracy = hits / res.size\n",
    "f_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm = confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.99      0.75       980\n",
      "          1       0.82      0.99      0.89      1135\n",
      "          2       0.84      0.74      0.79      1032\n",
      "          3       0.56      0.86      0.68      1010\n",
      "          4       0.65      0.89      0.75       982\n",
      "          5       0.88      0.44      0.59       892\n",
      "          6       0.92      0.78      0.85       958\n",
      "          7       0.87      0.76      0.81      1027\n",
      "          8       0.91      0.39      0.55       974\n",
      "          9       0.79      0.51      0.62      1009\n",
      "\n",
      "avg / total       0.78      0.74      0.73      9999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 969,    0,    0,    4,    1,    0,    3,    1,    2,    0],\n",
       "       [   5, 1120,    4,    3,    1,    0,    2,    0,    0,    0],\n",
       "       [ 100,   70,  766,   45,   16,    0,   11,    9,   10,    5],\n",
       "       [  69,   23,   31,  868,    2,    0,    2,    3,    2,   10],\n",
       "       [  23,   12,   14,   56,  872,    0,    1,    0,    4,    0],\n",
       "       [ 125,    9,    7,  218,   76,  390,   18,    6,   11,   32],\n",
       "       [  63,   11,   36,   25,   46,   24,  752,    0,    1,    0],\n",
       "       [  28,   36,   36,   78,   49,    5,    0,  779,    2,   14],\n",
       "       [ 189,   62,    8,  148,   45,   19,   29,   16,  384,   74],\n",
       "       [  24,   27,    6,  106,  237,    3,    0,   83,    7,  516]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
