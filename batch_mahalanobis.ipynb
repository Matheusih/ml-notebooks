{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = alexnet()\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        n = m.in_channels\n",
    "        for k in m.kernel_size:\n",
    "            n*=k\n",
    "        stdv = 1. / math.sqrt(n)\n",
    "        m.weight.data.uniform_(-stdv,stdv)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.uniform_(-stdv,stdv)\n",
    "            \n",
    "convs = []\n",
    "# list of a conv layers within alexnn\n",
    "for i,k in enumerate(model.modules()):\n",
    "    if isinstance(k, nn.Conv2d):\n",
    "        convs.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = convs[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0003, grad_fn=<ThAddBackward>)\n",
      "tensor(4.0939e-06, grad_fn=<ThAddBackward>)\n",
      "tensor(5.1202e-06, grad_fn=<ThAddBackward>)\n",
      "tensor(8.6133e-07, grad_fn=<ThAddBackward>)\n",
      "tensor(1.9252e-06, grad_fn=<ThAddBackward>)\n"
     ]
    }
   ],
   "source": [
    "for k in range(len(convs)):\n",
    "    l1 = convs[k].weight\n",
    "    dist = 0.0\n",
    "    for j in range(l1.shape[1]): # iterate over channels\n",
    "        X = l1[0][j].view(1,l1[0][j].shape[1]**2)  # gets first elem\n",
    "        for i,w in enumerate(l1): # iterates over filters 0-> 64\n",
    "            if i == 0:\n",
    "                continue\n",
    "            else:\n",
    "                y = w[0].view(1,w[j].shape[1]**2)\n",
    "                X = torch.cat((X,y))\n",
    "\n",
    "        VI = torch.inverse(cov(X)) #inverse of covariance matrix\n",
    "        for _input in X:\n",
    "            dist += _batch_mahalanobis(VI,_input)\n",
    "            #print(_batch_mahalanobis(VI,_input))\n",
    "    print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the covariance matrix of m\n",
    "def cov(m, rowvar=False):\n",
    "    if m.dim() > 2:\n",
    "        raise ValueError('m has more than 2 dimensions')\n",
    "    if m.dim() < 2:\n",
    "        m = m.view(1, -1)\n",
    "    if not rowvar and m.size(0) != 1:\n",
    "        m = m.t()\n",
    "    # m = m.type(torch.double)  # uncomment this line if desired\n",
    "    fact = 1.0 / (m.size(1) - 1)\n",
    "    m -= torch.mean(m, dim=1, keepdim=True)\n",
    "    mt = m.t()  # if complex: mt = m.t().conj()\n",
    "    return fact * m.matmul(mt).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _batch_mahalanobis(L, x):\n",
    "    r\"\"\"\n",
    "    Computes the squared Mahalanobis distance :math:`\\mathbf{x}^\\top\\mathbf{M}^{-1}\\mathbf{x}`\n",
    "    for a factored :math:`\\mathbf{M} = \\mathbf{L}\\mathbf{L}^\\top`.\n",
    "\n",
    "    Accepts batches for both L and x.\n",
    "    \"\"\"\n",
    "    # TODO: use `torch.potrs` or similar once a backwards pass is implemented.\n",
    "    flat_L = L.unsqueeze(0).reshape((-1,) + L.shape[-2:])\n",
    "    L_inv = torch.stack([torch.inverse(Li.t()) for Li in flat_L]).view(L.shape)\n",
    "    return (x.unsqueeze(-1) * L_inv).sum(-2).pow(2.0).sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.6474e-08, grad_fn=<SumBackward1>)\n",
      "tensor(1.9875e-07, grad_fn=<SumBackward1>)\n",
      "tensor(1.6561e-07, grad_fn=<SumBackward1>)\n",
      "tensor(6.8049e-07, grad_fn=<SumBackward1>)\n",
      "tensor(1.6184e-07, grad_fn=<SumBackward1>)\n",
      "tensor(1.1137e-07, grad_fn=<SumBackward1>)\n",
      "tensor(4.6328e-07, grad_fn=<SumBackward1>)\n",
      "tensor(1.9133e-07, grad_fn=<SumBackward1>)\n",
      "tensor(1.4527e-07, grad_fn=<SumBackward1>)\n",
      "tensor(4.9883e-08, grad_fn=<SumBackward1>)\n",
      "tensor(2.1414e-07, grad_fn=<SumBackward1>)\n",
      "tensor(5.9594e-07, grad_fn=<SumBackward1>)\n",
      "tensor(1.4073e-07, grad_fn=<SumBackward1>)\n",
      "tensor(3.4788e-07, grad_fn=<SumBackward1>)\n",
      "tensor(3.4324e-07, grad_fn=<SumBackward1>)\n",
      "tensor(1.4160e-06, grad_fn=<SumBackward1>)\n",
      "tensor(4.8469e-08, grad_fn=<SumBackward1>)\n",
      "tensor(3.9130e-07, grad_fn=<SumBackward1>)\n",
      "tensor(1.0504e-07, grad_fn=<SumBackward1>)\n",
      "tensor(2.3756e-07, grad_fn=<SumBackward1>)\n",
      "tensor(2.5613e-07, grad_fn=<SumBackward1>)\n",
      "tensor(6.8629e-07, grad_fn=<SumBackward1>)\n",
      "tensor(1.3376e-06, grad_fn=<SumBackward1>)\n",
      "tensor(2.0792e-07, grad_fn=<SumBackward1>)\n",
      "tensor(8.1522e-08, grad_fn=<SumBackward1>)\n",
      "tensor(3.7787e-07, grad_fn=<SumBackward1>)\n",
      "tensor(2.5706e-07, grad_fn=<SumBackward1>)\n",
      "tensor(1.8485e-07, grad_fn=<SumBackward1>)\n",
      "tensor(1.0014e-06, grad_fn=<SumBackward1>)\n",
      "tensor(5.8367e-08, grad_fn=<SumBackward1>)\n",
      "tensor(2.0405e-07, grad_fn=<SumBackward1>)\n",
      "tensor(1.7580e-07, grad_fn=<SumBackward1>)\n",
      "tensor(1.1690e-07, grad_fn=<SumBackward1>)\n",
      "tensor(2.1883e-07, grad_fn=<SumBackward1>)\n",
      "tensor(1.8237e-07, grad_fn=<SumBackward1>)\n",
      "tensor(1.4326e-07, grad_fn=<SumBackward1>)\n",
      "tensor(1.3620e-07, grad_fn=<SumBackward1>)\n",
      "tensor(1.0948e-07, grad_fn=<SumBackward1>)\n",
      "tensor(4.1091e-08, grad_fn=<SumBackward1>)\n",
      "tensor(6.7940e-08, grad_fn=<SumBackward1>)\n",
      "tensor(2.7100e-07, grad_fn=<SumBackward1>)\n",
      "tensor(2.1221e-07, grad_fn=<SumBackward1>)\n",
      "tensor(1.3293e-07, grad_fn=<SumBackward1>)\n",
      "tensor(9.6074e-08, grad_fn=<SumBackward1>)\n",
      "tensor(1.4587e-07, grad_fn=<SumBackward1>)\n",
      "tensor(1.6793e-07, grad_fn=<SumBackward1>)\n",
      "tensor(1.8268e-07, grad_fn=<SumBackward1>)\n",
      "tensor(3.7951e-07, grad_fn=<SumBackward1>)\n",
      "tensor(7.9721e-08, grad_fn=<SumBackward1>)\n",
      "tensor(9.2007e-08, grad_fn=<SumBackward1>)\n",
      "tensor(1.8003e-07, grad_fn=<SumBackward1>)\n",
      "tensor(3.1188e-07, grad_fn=<SumBackward1>)\n",
      "tensor(1.1893e-07, grad_fn=<SumBackward1>)\n",
      "tensor(9.0805e-08, grad_fn=<SumBackward1>)\n",
      "tensor(5.3350e-08, grad_fn=<SumBackward1>)\n",
      "tensor(5.1122e-07, grad_fn=<SumBackward1>)\n",
      "tensor(3.0234e-07, grad_fn=<SumBackward1>)\n",
      "tensor(1.0884e-07, grad_fn=<SumBackward1>)\n",
      "tensor(5.9306e-08, grad_fn=<SumBackward1>)\n",
      "tensor(3.0321e-07, grad_fn=<SumBackward1>)\n",
      "tensor(8.7628e-08, grad_fn=<SumBackward1>)\n",
      "tensor(9.3761e-08, grad_fn=<SumBackward1>)\n",
      "tensor(1.0298e-07, grad_fn=<SumBackward1>)\n",
      "tensor(4.3941e-07, grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "VI = torch.inverse(cov(X)) #inverse of covariance matrix\n",
    "for _input in X:\n",
    "    print(_batch_mahalanobis(VI,_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0474,  0.0017,  0.0472,  ...,  0.0012, -0.0300,  0.0392],\n",
       "        [-0.0177,  0.0123,  0.0127,  ...,  0.0099, -0.0233,  0.0153],\n",
       "        [ 0.0387, -0.0177, -0.0252,  ...,  0.0216, -0.0470, -0.0273],\n",
       "        ...,\n",
       "        [-0.0083, -0.0160,  0.0233,  ..., -0.0245,  0.0362,  0.0295],\n",
       "        [ 0.0460,  0.0058, -0.0124,  ..., -0.0407,  0.0351,  0.0305],\n",
       "        [ 0.0217, -0.0162, -0.0111,  ...,  0.0115,  0.0021,  0.0515]],\n",
       "       grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = X\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0031,  0.0523, -0.0470,  ..., -0.0072,  0.0420,  0.0186],\n",
       "        [-0.0177,  0.0123,  0.0127,  ...,  0.0099, -0.0233,  0.0153],\n",
       "        [ 0.0387, -0.0177, -0.0252,  ...,  0.0216, -0.0470, -0.0273],\n",
       "        ...,\n",
       "        [-0.0083, -0.0160,  0.0233,  ..., -0.0245,  0.0362,  0.0295],\n",
       "        [ 0.0460,  0.0058, -0.0124,  ..., -0.0407,  0.0351,  0.0305],\n",
       "        [ 0.0217, -0.0162, -0.0111,  ...,  0.0115,  0.0021,  0.0515]],\n",
       "       grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp2 = X\n",
    "tmp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0184, -0.0160, -0.0388,  ...,  0.0068, -0.0235, -0.0444],\n",
       "        [-0.0177,  0.0123,  0.0127,  ...,  0.0099, -0.0233,  0.0153],\n",
       "        [ 0.0387, -0.0177, -0.0252,  ...,  0.0216, -0.0470, -0.0273],\n",
       "        ...,\n",
       "        [-0.0083, -0.0160,  0.0233,  ..., -0.0245,  0.0362,  0.0295],\n",
       "        [ 0.0460,  0.0058, -0.0124,  ..., -0.0407,  0.0351,  0.0305],\n",
       "        [ 0.0217, -0.0162, -0.0111,  ...,  0.0115,  0.0021,  0.0515]],\n",
       "       grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
